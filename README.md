ССЫЛКА НА ПРИЛОЖЕНИЕ В СТРИМЛИТ: https://autopricepredictiongit-hse.streamlit.app
(В качестве csv лучше загружать таблицу, которую мы скачивали изначально в ноутбуке:
https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_test.csv
Эта таблица есть в репозитории под названием test.csv

<h1> Вывод
  
   

<h5>

1) Я впервые составил отчет о данных с помощью ydata-profiling. Это оказалось очень удобной функцией, которая может подсветить такие важные моменты в датасете, как: 
    - дупликаты
    - пропущенные значения
    - количество, типы признаков и распределение внутри них (очень удобно сразу посмотреть на аномалии, или несбалансированность классов, например), да и просто статистику признаков (минимальные и максимальные значения, количество уникальных значений)
    - корреляции между признаками (это очень полезная функция, с помщью которой можно значительно облегчить анализ данных)

2) Работа с признаками:
    - Удалил дубликаты и заменил NaN на медианные значения (впервые узнал о том, что стоит создать отдельный признак с указанием на то, что в этой записи было пропущенное значение, которое мы заменили медианой)
    - Вычленил из "текстовых" признаков числа с помощью регулярных выражений - это было интересно, но пришлось подбирать нужную регулярку довольно долго (зато теперь это будет проще)

3) Визуализации:
    - Построил матирцу парных корреляций для признаков с помощью seaborn (полезно)
    - Узнал больше о разных корреляциях (Спирмена, Кенделла и Пирсона) + сделал руками свою версию кор-ии Спирмена, что очень сильно углубило интуицуию в этом плане.
    - Построил разные другие графики, чтобы лучше понимать данные. Открыл для себя, что "зависимость" или корреляция может проявляться гораздо более явно, если взять не чистый признак, а некую функцию от него (например, возвести в квадрат).
    - Воспользовался phi корреляцией и посмотрел, как могут влиять аномальные значения на корреляцию признаков (спойлер: влияют плохо, лучше их избегать).

4) Обучение моделей:
    - Построил базовую LinearRegression модель без каких-либо гиперпараметров (R2 = 0.59, MSE = 230041438298)
    - Узнал про adjusted-R2, который штрафует модель за избыток признаков. Это может быть полезно при OneHotEncoding, после которого создается очень много столбцов
    - Посмотрел, как можно увеличить интуицию о модели за счет вывода итоговых весов модели. Перед этим обязательно нужно отнормировать данные, чтобы веса можно было сравнивать между собой.
    - Построил Lasso-регрессию. (R9 = 0.59, MSE = 230042177331)
    - Попробовал разные виды регуляризации на практике, увидел, как они влияют на итоговые веса. Узнал о L0 регуляризации и реализовал её. (R2 = 0.59, MSE = 230280648356)
    - Перебрал параметры с помощью GridSearch - больше понял про гиперпараметры линейных моделей.
    - Обработал категориальные признаки с помощью OHE.
    - После добавления категориальных фич модель Ridge регрессии дала хорошие метрики (R2 = 0.78, MSE = 125886792392)

5) Создание признаков:
    - Попробовал разные гипотезы и убедился в том, что иногда очень весомый для целевой переменной признак может находиться во взаимодействии двух других признаков или быть скрыт за какой-то функцией.
    - Узнал о том, что можно прибегать к логарифмированию признака, чтобы не было аномальных значений (не думаю, что линейная модель может очень хорошо уловить логарифм, но если добавить несколько слоев, то это должно сработать еще лучше, наверное)
    - Понял, что очень эффективным методом кодирования категориальных признаков может быть Mean Target Encoding, но с ним нужно быть аккуратным, чтобы не допустить data leakage. В данной задаче это кодирование признаков подходит идеально, потому что мы кодируем модель автомобиля, а реальность жизни такова, что средняя цена на какую-то модель всегда примерно одна и та же. То есть, нельзя купить БМВ за 75000, а Maruti за 10+ млн. У любого человека, связанного с авторынком есть эта интуиция, а у модели её нет, поэтому мы даём ей её за счет данного энкодинга. Главное чтобы тестовая выборка опиралась в данном случае только на трейн, иначе будет переобучение.
    - В итоге лучшая модель получилась именно за счет новых признаков, а не только из-за выбранной модели. Можно сказать, что именно создание новых признаков дало наибольший прирост к метрике (и качеству модели соответственно). Удалось добиться R2 = 0.82, MSE = 64986805968 и MAE = 128452 (то есть, модель будет ошибаться в среднем примерно на 128 тысяч рублей, учитывая что есть и очень дорогие и очень дешевые машины), по-моему, это неплохой результат.

6) Бизнес-метрики и сохранение результатов:
    - Придумал свою бизнес-метрику, это было интересно с точки зрения математики. Вряд ли получилась очень наглядная и устойчивая метрика, но её можно было бы использовать в каких-то специфических случаях.
    - Впервые создал целый пайплайн для модели. Это было тяжело и очень долго, поскольку на протяжении ноутбука данные претерпевали разные изменения, и собрать это все в единое целое не было простой задачей. Однако на выходе получился полноценный объект класса Pipeline, который уже готов к использованию и предсказанию цен на автомобиль. Все, что остается это просто сделать fit на трейне и predict на тесте.
    - Также впервые сохранил (и попробовал сразу загрузить для использования) лучшую модель в pickle - полезно для дальнейшего использования (правда это не самый надежный способ, судя по всему, но легко работает)
    - Отдельно хочется сказать, что предсказания модели могут быть отрицательными, что противоречит логике реального мира. Это является следствием линейных моделей, поскольку так обучены веса. В теории, это можно было бы исправить через конструкцию y_pred = min(0, y_pred), но мне показалось, что это будет не сосвем честное предсказание модели, поэтому пока что такое не реализовано.

7) Streamlit:
    - Приложение получилось достаточно удобным и выполняющим весь требуемый функционал. Можно загрузить таблицу для визуализации данных, таблицу для предсказания цен, загрузить параметры машины, цену которой мы хотим предсказать, а также можно посмотреть визуализацию весов модели.
    - Достаточно хорошо получилось визуализировать phik-кореляцию, распределение целевой переменной и веса модели. А парные графики было сложнее визуализировать из-за того, что для этого неоходимо провести обработку данных наполовину. То есть, нельзя было воспользоваться методом model.named_steps['transformer'].transform(df), поскольку такая трансформация видоизменяла признаки слишком сильно (в готовый для предсказания вид), а нужно было что-то посередине. Из этого я понял, что Pipeline лучше разбивать на много шагов, чтобы потом можно было их повторить при переиспользовании модели.
    - Я не заметил особых ограничений в использовании streamlit. Этот сервис предоставляет достаточно гибкий функционал. Допускаю, что я просто не нашел некоторые методы для лучшей компоновки блоков на странице, но даже так итоговая страница выглядит хорошо и удобно.
    - При дальнейшем улучшении этого приложения я бы обратил внимание на динамическое предсказание цены конкретного автомобиля. Допустим, добавил бы ползунок на числовые признаки (чтобы облегчить выбор), после изменения которого тут же менялось бы предсказание (возникает вопрос - хватит ли на это ресурсов стримлита или это будет грузиться слишком долго). Также я бы переработал компоновку логических секций приложения, чтобы облегчить опыт использования.

<h5> P.S. Генеративные нейросети были использованы преимущественно для получения знаний, а не генерации конкретных кусков кода. Хотя в каких-то моментах вроде словаря со странами прозиводителей автомобилей чатгпт был очень полезен. Все такие моменты я отметил комментарием о том, что использовал нейросеть.
